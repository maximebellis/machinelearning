{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    X = data.drop('Revenue', axis=1) \n",
    "    y = data['Revenue']  \n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoded features function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(X):\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Label encoding for 'Month'\n",
    "    X['Month'] = label_encoder.fit_transform(X['Month'])\n",
    "\n",
    "    # Label encoding for 'VisitorType'\n",
    "    X['VisitorType'] = label_encoder.fit_transform(X['VisitorType'])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    z = np.clip( z, -500, 500 )           # protect against overflow\n",
    "    g = 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My dense vector function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dense_v(A_in, W, b, g):\n",
    "    Z = np.matmul(A_in, W) + b\n",
    "    A_out = g(Z)\n",
    "    return(A_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My sequential function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sequential_v(X, W1, b1, W2, b2, W3, b3):\n",
    "    A1 = my_dense_v(X,  W1, b1, relu)\n",
    "    A2 = my_dense_v(A1, W2, b2, relu)\n",
    "    A3 = my_dense_v(A2, W3, b3, sigmoid)\n",
    "    return(A3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Máté Keller\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\Máté Keller\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "309/309 [==============================] - 1s 987us/step - loss: 0.3116\n",
      "Epoch 2/20\n",
      "309/309 [==============================] - 0s 971us/step - loss: 0.2612\n",
      "Epoch 3/20\n",
      "309/309 [==============================] - 0s 981us/step - loss: 0.2498\n",
      "Epoch 4/20\n",
      "309/309 [==============================] - 0s 961us/step - loss: 0.2439\n",
      "Epoch 5/20\n",
      "309/309 [==============================] - 0s 981us/step - loss: 0.2397\n",
      "Epoch 6/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2354\n",
      "Epoch 7/20\n",
      "309/309 [==============================] - 0s 955us/step - loss: 0.2335\n",
      "Epoch 8/20\n",
      "309/309 [==============================] - 0s 955us/step - loss: 0.2307\n",
      "Epoch 9/20\n",
      "309/309 [==============================] - 0s 951us/step - loss: 0.2286\n",
      "Epoch 10/20\n",
      "309/309 [==============================] - 0s 964us/step - loss: 0.2251\n",
      "Epoch 11/20\n",
      "309/309 [==============================] - 0s 948us/step - loss: 0.2244\n",
      "Epoch 12/20\n",
      "309/309 [==============================] - 0s 981us/step - loss: 0.2210\n",
      "Epoch 13/20\n",
      "309/309 [==============================] - 0s 961us/step - loss: 0.2209\n",
      "Epoch 14/20\n",
      "309/309 [==============================] - 0s 956us/step - loss: 0.2178\n",
      "Epoch 15/20\n",
      "309/309 [==============================] - 0s 951us/step - loss: 0.2168\n",
      "Epoch 16/20\n",
      "309/309 [==============================] - 0s 984us/step - loss: 0.2152\n",
      "Epoch 17/20\n",
      "309/309 [==============================] - 0s 948us/step - loss: 0.2133\n",
      "Epoch 18/20\n",
      "309/309 [==============================] - 0s 968us/step - loss: 0.2124\n",
      "Epoch 19/20\n",
      "309/309 [==============================] - 0s 951us/step - loss: 0.2108\n",
      "Epoch 20/20\n",
      "309/309 [==============================] - 0s 966us/step - loss: 0.2088\n",
      "Custom Model Accuracy: 0.8868613138686131\n",
      "78/78 [==============================] - 0s 792us/step\n",
      "TensorFlow Model Accuracy: 0.8868613138686131\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y = load_data(\"dataset.csv\")\n",
    "X_encoded = encode_features(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define and train TensorFlow model\n",
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(17,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name=\"my_model\")\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "model.fit(X_train_scaled, y_train, epochs=20)\n",
    "\n",
    "# Extract weights after training\n",
    "[layer1, layer2, layer3] = model.layers\n",
    "W1_tmp, b1_tmp = layer1.get_weights()\n",
    "W2_tmp, b2_tmp = layer2.get_weights()\n",
    "W3_tmp, b3_tmp = layer3.get_weights()\n",
    "\n",
    "# Use custom model for predictions on test data\n",
    "custom_predictions = my_sequential_v(X_test_scaled, W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp)\n",
    "custom_predicted_classes = (custom_predictions > 0.5).astype(int)\n",
    "custom_accuracy = accuracy_score(y_test, custom_predicted_classes)\n",
    "print(\"Custom Model Accuracy:\", custom_accuracy)\n",
    "\n",
    "# TensorFlow model predictions on test data\n",
    "tf_predictions = model.predict(X_test_scaled)\n",
    "tf_predicted_classes = (tf_predictions > 0.5).astype(int)\n",
    "tf_accuracy = accuracy_score(y_test, tf_predicted_classes)\n",
    "print(\"TensorFlow Model Accuracy:\", tf_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction = my_sequential_v(X, W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp )\n",
    "Prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity, Specificity and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.72\n",
      "Specificity: 0.91\n",
      "F1 Score: 0.61\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(tf_predicted_classes, y_test)\n",
    "\n",
    "tn = conf_matrix[0, 0]  # True Negative\n",
    "fp = conf_matrix[0, 1]  # False Positive\n",
    "tp = conf_matrix[1, 1]  # True Positive\n",
    "fn = conf_matrix[1, 0]  # False Negative\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "specificity = tn/(tn+fp)\n",
    "\n",
    "f1 = f1_score(tf_predicted_classes, y_test)\n",
    "\n",
    "print(\"Sensitivity: {:.2f}\".format(sensitivity))\n",
    "print(\"Specificity: {:.2f}\".format(specificity))\n",
    "print(\"F1 Score: {:.2f}\".format(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
