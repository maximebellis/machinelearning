{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    X = data.drop('Revenue', axis=1) \n",
    "    y = data['Revenue']  \n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoded features function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(X):\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Label encoding for 'Month'\n",
    "    X['Month'] = label_encoder.fit_transform(X['Month'])\n",
    "\n",
    "    # Label encoding for 'VisitorType'\n",
    "    X['VisitorType'] = label_encoder.fit_transform(X['VisitorType'])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    z = np.clip( z, -500, 500 )           # protect against overflow\n",
    "    g = 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My dense vector function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dense_v(A_in, W, b, g):\n",
    "    Z = np.matmul(A_in, W) + b\n",
    "    A_out = g(Z)\n",
    "    return(A_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My sequential function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sequential_v(X, W1, b1, W2, b2, W3, b3):\n",
    "    A1 = my_dense_v(X,  W1, b1, relu)\n",
    "    A2 = my_dense_v(A1, W2, b2, relu)\n",
    "    A3 = my_dense_v(A2, W3, b3, sigmoid)\n",
    "    return(A3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "309/309 [==============================] - 1s 1ms/step - loss: 0.3181\n",
      "Epoch 2/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2587\n",
      "Epoch 3/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2483\n",
      "Epoch 4/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2434\n",
      "Epoch 5/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2393\n",
      "Epoch 6/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2362\n",
      "Epoch 7/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2323\n",
      "Epoch 8/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2298\n",
      "Epoch 9/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2270\n",
      "Epoch 10/20\n",
      "309/309 [==============================] - 0s 2ms/step - loss: 0.2250\n",
      "Epoch 11/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2237\n",
      "Epoch 12/20\n",
      "309/309 [==============================] - 1s 2ms/step - loss: 0.2213\n",
      "Epoch 13/20\n",
      "309/309 [==============================] - 0s 2ms/step - loss: 0.2190\n",
      "Epoch 14/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2185\n",
      "Epoch 15/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2144\n",
      "Epoch 16/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2140\n",
      "Epoch 17/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2113\n",
      "Epoch 18/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2105\n",
      "Epoch 19/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2089\n",
      "Epoch 20/20\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.2070\n",
      "Custom Model Accuracy: 0.883617193836172\n",
      "78/78 [==============================] - 0s 1ms/step\n",
      "TensorFlow Model Accuracy: 0.883617193836172\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y = load_data(\"dataset.csv\")\n",
    "X_encoded = encode_features(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define and train TensorFlow model\n",
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(17,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name=\"my_model\")\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "model.fit(X_train_scaled, y_train, epochs=20)\n",
    "\n",
    "# Extract weights after training\n",
    "[layer1, layer2, layer3] = model.layers\n",
    "W1_tmp, b1_tmp = layer1.get_weights()\n",
    "W2_tmp, b2_tmp = layer2.get_weights()\n",
    "W3_tmp, b3_tmp = layer3.get_weights()\n",
    "\n",
    "# Use custom model for predictions on test data\n",
    "custom_predictions = my_sequential_v(X_test_scaled, W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp)\n",
    "custom_predicted_classes = (custom_predictions > 0.5).astype(int)\n",
    "custom_accuracy = accuracy_score(y_test, custom_predicted_classes)\n",
    "print(\"Custom Model Accuracy:\", custom_accuracy)\n",
    "\n",
    "# TensorFlow model predictions on test data\n",
    "tf_predictions = model.predict(X_test_scaled)\n",
    "tf_predicted_classes = (tf_predictions > 0.5).astype(int)\n",
    "tf_accuracy = accuracy_score(y_test, tf_predicted_classes)\n",
    "print(\"TensorFlow Model Accuracy:\", tf_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction = my_sequential_v(X, W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp )\n",
    "Prediction.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
